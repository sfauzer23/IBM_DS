{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "686851bb",
   "metadata": {},
   "source": [
    "# Lesson 2: Working with different file formats\n",
    "\n",
    "Objective:\n",
    "- Reading data from CSV in Python\n",
    "- Reading data from JSON in Python\n",
    "- Reading data from XLSX in Python\n",
    "- Reading data from XML in Python\n",
    "- Reading data from Binary in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac43824",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89706b53",
   "metadata": {},
   "source": [
    "### Reading Data from CSV in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf618af5",
   "metadata": {},
   "source": [
    "We already know how to do this unsing the pd.read_csv() command with options such as headers. If there are no headers in the file then a df will be created using the first row as the header, this can be corrected using the columns method to set the column. We can slice the dataframe using the column name or methods such as df.loc[] or df.iloc[] where loc i slabel based and iloc is index based."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e060084a",
   "metadata": {},
   "source": [
    "Below we construct a dataframe and use the transform method with a lambda function to efficiently change our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77f6d5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a730a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]), columns=['a', 'b', 'c'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2e8fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.transform(func = lambda x : x + 10)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3bb82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df.transform(func = ['sqrt']) # This has square root everything with the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcf9fde",
   "metadata": {},
   "source": [
    "### Reading Data from JSON in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c38220d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7eb5fddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "person = {\n",
    "    'first_name' : 'Mark',\n",
    "    'last_name' : 'abc',\n",
    "    'age' : 27,\n",
    "    'address': {\n",
    "        \"streetAddress\": \"21 2nd Street\",\n",
    "        \"city\": \"New York\",\n",
    "        \"state\": \"NY\",\n",
    "        \"postalCode\": \"10021-3100\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25dd259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('person.json', 'w') as f:  # writing JSON object\n",
    "    json.dump(person, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d847369b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('person.json', 'r') as openfile:  # Reading the JSON object\n",
    "  \n",
    "    # Reading from json file \n",
    "    json_object = json.load(openfile) \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4de7193",
   "metadata": {},
   "source": [
    "### Reading Data from XLSX in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832ed386",
   "metadata": {},
   "source": [
    "This is done by just using the pd.read_excel() method from here you can just use the file name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eb6e2e",
   "metadata": {},
   "source": [
    "### Reading Data from XML in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94efcf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET # Writing XML file\n",
    "\n",
    "# create the file structure\n",
    "employee = ET.Element('employee')\n",
    "details = ET.SubElement(employee, 'details')\n",
    "first = ET.SubElement(details, 'firstname')\n",
    "second = ET.SubElement(details, 'lastname')\n",
    "third = ET.SubElement(details, 'age')\n",
    "first.text = 'Shiv'\n",
    "second.text = 'Mishra'\n",
    "third.text = '23'\n",
    "\n",
    "# create a new XML file with the results\n",
    "mydata1 = ET.ElementTree(employee)\n",
    "# myfile = open(\"items2.xml\", \"wb\")\n",
    "# myfile.write(mydata)\n",
    "with open(\"new_sample.xml\", \"wb\") as files:\n",
    "    mydata1.write(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5adf2f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(\"new_sample.xml\") # Reading data\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727e8074",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"firstname\", \"lastname\", \"age\"] # Setting the dataframe\n",
    "datatframe = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfa0d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in root: # Inputting the data into the dataframe from the XML file.\n",
    "    # Extract text from each element\n",
    "    firstname = node.find(\"firstname\").text\n",
    "    lastname = node.find(\"lastname\").text\n",
    "    age = node.find(\"age\").text\n",
    "    # title = node.find(\"title\").text\n",
    "    # division = node.find(\"division\").text\n",
    "    # building = node.find(\"building\").text\n",
    "    # room = node.find(\"room\").text\n",
    "    \n",
    "    # Create a DataFrame for the current row\n",
    "    row_df = pd.DataFrame([[firstname, lastname, age]], columns=columns)\n",
    "    \n",
    "    # Concatenate with the existing DataFrame\n",
    "    datatframe = pd.concat([datatframe, row_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250cd472",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_xml(\"new_sample.xml\") # Instead of that this cab  work as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2902e74c",
   "metadata": {},
   "source": [
    "When it comes to saving data you can use df_to_csv() or json or excel or hdf or sql depending on what you want with methods like index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2015d3c8",
   "metadata": {},
   "source": [
    "### Reading Data from Binary in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1764d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b98142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dog.jpg', <http.client.HTTPMessage at 0x2436a8a18d0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request # Get an Image\n",
    "urllib.request.urlretrieve(\"https://hips.hearstapps.com/hmg-prod.s3.amazonaws.com/images/dog-puppy-on-garden-royalty-free-image-1586966191.jpg\", \"dog.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358088a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('./dog.jpg','r') # Open an image and show it\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba54c6c1",
   "metadata": {},
   "source": [
    "### Gaining descriptive statistics of a dataset in python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070fbf6a",
   "metadata": {},
   "source": [
    "Use methods like df.head(), df.info(), df.describe(), missing_data = df.isnull() to find missing data. df.dtypes to check data types."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
